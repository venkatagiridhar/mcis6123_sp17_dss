{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURE 5 NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "* introduction to decision making and decision theory\n",
    "* decisions under ignorance\n",
    "* decisions with probabilities\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* exposure to decision making and the factors influencing decisions\n",
    "* introduction to decision theory concepts\n",
    "* basic modeling for decisions with uncertainty (maximax, minimax, maximin algorithms)\n",
    "* basic modeling for decisions with probabilities (expected value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION MAKING\n",
    "\n",
    "In thinking about decision making, we will set up a context in which to frame all subsequent discussion on the topic.\n",
    "\n",
    "A common decision making context we will be dealing with involves a decision maker or _actor_ and _nature_.  The context could involved one or more actors against nature, and as in a game, one or more actors against each other.  However, we'll restrict our discussions to a single actor and nature. \n",
    "\n",
    "There are various states of nature or _events_, that may influence the behavior of the actor, and various _outcomes_ are possible depending on all the modeled events that could occur.  Each outcome has a perceived value to the actor, the choices the actor makes represent the _acts_ of the decision maker.\n",
    "\n",
    "<!-- rational actor theory reference -->\n",
    "We are assuming that the decision maker is a _rational actor_ -- that is the decisions are made consistently based on preference, and that decisions are made within the framework of _reason_ and _fact_.  While reason and fact are central to the decision making process of the rational actor, we assume the actor will explore all possible choices and apply preferences to their decisions based on the _desired_ outcome (e.g. maximize loss, minimize risk, etc).\n",
    "\n",
    "### FACTORS INFLUENCING DECISION MAKING\n",
    "\n",
    "In extending the framework for decision making, we have to explore core factors that influence decisions. \n",
    "\n",
    "<!-- Utility \n",
    "_Preferences_ \n",
    "* preferences -->\n",
    "* **outcomes** : the results of the various events of nature on the actor\n",
    "* **utility** : a (typically numeric) measure of value for a particular event \n",
    "* **loss or cost** : the inverse of utility, or the measure of the cost of an event; for example the \"cost\" associated with purchasing an umbrella may be compared to its utility; \"loss\" can also refer to what what one may lose of they do not make a specific decision\n",
    "<!--* cost :--> \n",
    "* **risk** : the probability associated with an event happening; for example the _risk_ of it raining tomorrow is equivalent to asking \"what is the probability it will rain tomorrow\"\n",
    "\n",
    "\n",
    "\n",
    "### HIGH-LEVEL PROCESSES\n",
    "\n",
    "At the most basic level a decision process can be partitioned in 8 steps enumerated below.  Most processes will begin with an identification of the _decision makers_ (actors) and _stakeholders_ (which may or may not be the actors).  For example, in the context of managing an investment portfolio, the ultimate decision makers might be the investment managers, while the stakeholders will be the investors who are placing money into the fund with the expectation of the highest possible return on their investment. The basic process for decision making is given below:\n",
    "\n",
    "![Basic decision making process.](./assets/decision_flow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "There are four concepts typically used to frame the decision context:\n",
    "\n",
    "* **acts** - _actions taken by the decision maker_\n",
    "* **events** - _the states of nature that may affect the decision maker, these states are not under the control of the decision maker (e.g. the decion maker cannot control the weather)_\n",
    "* **outcomes** - _the consequence or effect of both nature and acts_\n",
    "* **payoff** - _the actual or perceived value the decision maker places on the outcomes_\n",
    "\n",
    "Crucial to this framework is the concept that there are consequences of _acts_ that have value to the decision maker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PAYOFF TABLE\n",
    "One way to model this problem is with a _payoff table_. Such a payoff table can be modeled with $a$ denoting the decision (**action**) and $n$ the state of nature (**events**).  Let $p_{a_i,n_j}$ be the payoff for each of the acts $a_i$ and states of nature $n_j$. For now we will assume payoff represents the preference of the decision maker given the alternative decisions and the states of nature.  A payoff table might look like this:\n",
    "\n",
    "| $^n / _a$ | $n_1$ | $n_2$ | $\\ldots$ | $n_m$ |\n",
    "|:--------:|:-----:|:-----:|:-----:|:-----:|\n",
    "| $a_1$ | $p_{a_1,n_1}$ | $p_{a_1,n_2}$ | $\\ldots$ | $p_{a_1,n_m}$ |\n",
    "| $a_2$ | $p_{a_2,n_1}$ | $p_{a_2,n_2}$ | $\\ldots$ | $p_{a_2,n_m}$ |\n",
    "| $\\ldots$ | $\\ldots$ | $\\ldots$ | $\\ddots$ | $\\ldots$ |\n",
    "| $a_n$ | $p_{a_n,n_1}$ | $p_{a_n,n_2}$ | $\\ldots$ | $p_{a_n,n_m}$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### EXAMPLE\n",
    "\n",
    "Let's explore a simple example. Suppose it is to snow tomorrow.  You can wear snow boots, but you find them to be hot, bulky and a burden, thus you don't  usually _like_ to wear boots.  This problem can be modeled thus,\n",
    "\n",
    "* acts (choices) \n",
    "    * wear boots\n",
    "    * don't wear boots\n",
    "* events\n",
    "    * snow\n",
    "    * no snow\n",
    "* outcomes\n",
    "    * wear boots, snow\n",
    "    * wear boots, no snow\n",
    "    * don't wear boots, snow\n",
    "    * don't wear boots, no snow \n",
    "\n",
    "So far the set up of the problem would look like this in the payoff table:\n",
    "\n",
    "|         | snow | no snow |\n",
    "|:-------:|:----:|:-------:|\n",
    "|**boots**    |$p_{ b, s}$|$p_{\\neg b,s}$|\n",
    "|**no boots** |$p_{\\neg b, s}$|$p_{\\neg b, \\neg s}$|\n",
    "\n",
    "How do we make a decision?  What criterion will we use to make the _right_ decision?  _For now_ we will say that we want to make the **decision with the highest payoff**, eventhough this may or may not be the desired strategy in every case as we shall see later, based on preferences, risk tolerances, assumptions about the state of nature, etc.  \n",
    "\n",
    "Let's assume that for now the payoff can be numerically modeled as _an integer representing the decision maker's satisfaction or perceived benefit_, where a negative value represents  a negative benefit for the decision maker, while a positive value, positive benefit. Though these numbers are modeled as integers, they do not have to be, as in the case where payoffs are monetary. \n",
    "\n",
    "* payoff\n",
    "    * $r_{b,s} \\rightarrow  0$; equivalent to when outcome = wear boots, snow.  You are satisfied that your feet are warm and dry, even if you don't like to wear boots.\n",
    "    * $r_{b,\\neg s} \\rightarrow -10$; equivalent to when outcome = wear boots, no snow.  You you are inconveniently forced to wear something that is uncomfortable and not need, thus you are _not at all satisfied that day_.\n",
    "    * $r_{\\neg b, s} \\rightarrow -5$; equivalent to when outcome = don't wear boots, snow.  You are inconvenienced because your feet are cold and maybe wet because it snowed and you failed to wear your boots, thus you are not satisified, but you still place some value on not having to wear boots at all!\n",
    "    * $r_{\\neg b, \\neg s} \\rightarrow 5$; equivalent to when outcome = don't wear boots, no snow.  You are very satisfied since it didn't snow and you didn't wear your boots.\n",
    "\n",
    "The final payoff table will look like this:\n",
    "\n",
    "|         | snow | no snow |\n",
    "|:-------:|:----:|:-------:|\n",
    "|**boots**    | $0$  | $-10$ |\n",
    "|**no boots** | $-5$ | $5$ |\n",
    "\n",
    "Let's assume also (for now at least), that we do not know the likelihood of snow or no snow.  In this state, we say we are making a _decision under ignorance_.  How do we decide to wear boots or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISIONS UNDER IGNORANCE\n",
    "\n",
    "When we say we do not know the probability or likelihood of rain, we are forced into making what is called a _decision under ignorance_ -- that is we have **no information** about what the likelihoods of the states of nature will be that could influence our decision.\n",
    "\n",
    "There are four common strategies to consider when making decisions under ignorance.  They are enumerated in the table below:\n",
    "\n",
    "| decision rule | strategy characterization | explanation |\n",
    "|:-------------:|:---------------------:|---------------------------------------|\n",
    "|maximin        | pessimism             |**best of the worst case** |\n",
    "|maximax        | extreme optimism      |**best of the best case**  |\n",
    "|minimax        | caution               |**least of the best case** |\n",
    "|minimax regret | caution               |**least of the best case with regret criterion** | \n",
    "\n",
    "Mathematically, these decisions can be written with just $\\mathrm{min}$, $\\mathrm{max}$, $\\mathrm{argmin}$ and $\\mathrm{argmax}$.\n",
    "\n",
    "| decision rule | binary action formalism |\n",
    "|:-------------:|:--------------------:|\n",
    "|maximin        | $$\\mathrm{argmax} \\min p_{a, n}$$ |\n",
    "|maximax        | $$\\mathrm{argmax} \\max p_{a, n}$$ |\n",
    "|minimax        | $$\\mathrm{argmin} \\max p_{a, n}$$ |\n",
    "|minimax regret | $$\\mathrm{argmin} \\max \\hat{p}_{a, n}$$  |\n",
    "\n",
    "Note: $\\hat{p}$ is the regret calculation described in the next section.\n",
    "\n",
    "We an now return to our example scenario and make a decision as to what we should do under various rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAXIMIN**\n",
    "With **maximin** we will take the best of the worst case payoffs, that is for each possibile decision, we will find the set of all of the worst of them, then pick the best of that set. Given the payoff table:\n",
    "\n",
    "|         | snow | no snow | **maximin strategy** |\n",
    "|:-------:|:----:|:-------:|:-----:|\n",
    "|**boots**    | $0$  | $-10$ | $-10$ |\n",
    "|**no boots** | $-5$ | $5$ | $\\bf{-5}$ |\n",
    "\n",
    "Using the maximin strategy, the best of the worst case is $-5$, thus we would *not wear boots*. Notice that this strategy does not protect your feet eventhough it assumes a pessimistic stance in the face of ignorance about the rain forecast.\n",
    "\n",
    "**MAXIMAX**\n",
    "With the **maximax** strategy,  we will take a wildly optimistic, opportunistic and more blindly risky posture to  decision making.  In fact, we will be na&iuml;vely positive to any of the realistic possibilities. In this case, we are *not going to wear boots* -- we value satisfaction and expect the best of the weather.\n",
    "\n",
    "\n",
    "|         | snow | no snow | **maximax strategy** |\n",
    "|:-------:|:----:|:-------:|:-----:|\n",
    "|**boots**    | $0$  | $-10$ | $0$ |\n",
    "|**no boots** | $-5$ | $5$ | $\\bf{5}$ |\n",
    "\n",
    "Under maximax, we would **not wear boots*.\n",
    "\n",
    "**MINIMAX**\n",
    "In order to be a bit more cautions, but also hold _some_ hope for good weather, we could employ the minimax strategy.  Here we will take the worst of the best ... holding out for the possibility that it might rain, but trying also to be optimistic that it won't.\n",
    "\n",
    "|         | snow | no snow | **minimax strategy** |\n",
    "|:-------:|:----:|:-------:|:-----:|\n",
    "|**boots**    | $0$  | $-10$ | $\\bf{0}$ |\n",
    "|**no boots** | $-5$ | $5$ | $5$ |\n",
    "\n",
    "Thus under minimax, we would **wear boots**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS / REGRET TABLE\n",
    "\n",
    "Computing the loss table requires we take the **payoff table** and compute the difference between the _maximum_ payoff and all the other payoffs. Building loss (regret) table allows one to calculate losses for the _minimax regret_ strategy.  Recall, minimax considers the best of the worst case scenarios, and in order to consider the worst cases, we may also will need to consider losses within the framework of what you could be losing if you take the best possible action for all actions and weigh it against the action under consideration.  Concretely, if the maximum payoff for a particular set of actions is $100$ and the payoff for a specific action is $25$, then the reget is $75$.  On the other hand, if the payoff is $-25$, the regret is $100$ .    Thus, we'd construct the regret table:\n",
    "\n",
    "\n",
    "| $^n / _a$ | $n_1$ | $n_2$ | $\\ldots$ | $n_m$ |\n",
    "|:--------:|:-----:|:-----:|:-----:|:-----:|\n",
    "| $a_1$ | $\\mathrm{argmax}_{n_1} - p_{a_1,n_1}$ | $\\mathrm{argmax}_{n_2} - p_{a_1,n_2}$ | $\\ldots$ | $\\mathrm{argmax}_{n_m} - p_{a_1,n_m}$ |\n",
    "| $a_2$ | $\\mathrm{argmax}_{n_1} - p_{a_2,n_1}$ | $\\mathrm{argmax}_{n_2} - p_{a_2,n_2}$ | $\\ldots$ | $\\mathrm{argmax}_{n_m} - p_{a_2,n_m}$ |\n",
    "| $\\ldots$ | $\\ldots$ | $\\ldots$ | $\\ddots$ | $\\ldots$ |\n",
    "| $a_n$ | $\\mathrm{argmax}_{n_1} - p_{a_n,n_1}$ | $\\mathrm{argmax}_{n_2} - p_{a_n,n_2}$ | $\\ldots$ | $\\mathrm{argmax}_{n_m} - p_{a_n,n_m}$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINIMAX REGRET**\n",
    "We mentioned above the _minimax_ strategy,  and now that we know about regrets, we introduce the _minimax regret_ strategy which is computed not from the payoff table, but from the loss/regret table. Like _minimax_, we are still cautious, and also hold _some_ hope for good weather,  but look at the _loss_ or _regret_ as computed above instead of the _payoff_.\n",
    "\n",
    "Thus the regret table looks like:\n",
    "\n",
    "\n",
    "\n",
    "|         | snow | no snow | minimax regret |\n",
    "|:-------:|:----:|:-------:|:--------------:|\n",
    "|**boots**    | $0$  | $15$ | $\\bf{0}$ |\n",
    "|**no boots** | $5$ | $0$ | $5$ |\n",
    "\n",
    "The decision would be to **wear boots**, the minimum of all the maximum regrets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXAMPLE 2**\n",
    "\n",
    "We've shown a simple example, but let's bring this into a more significant exploration of the concepts with the regret table.  Let's consider the following example (inspired by [https://people.richland.edu/james/summer02/m160/decision.html](https://people.richland.edu/james/summer02/m160/decision.html)):\n",
    "\n",
    ">Zed and Adrian and run a small bicycle shop called \"Z to A Bicycles\". They must order bicycles for the coming season. Orders for the bicycles must be placed in quantities of twenty (20). The cost per bicycle is \\$70 if they order 20, \\$67 if they order 40, \\$65 if they order 60, and \\$64 if they order 80. The bicycles will be sold for \\$100 each. Any bicycles left over at the end of the season can be sold (for certain) at \\$45 each. If Zed and Adrian run out of bicycles during the season, then they will suffer a loss of \"goodwill\" among their customers. They estimate this goodwill loss to be \\$5 per customer who was unable to buy a bicycle. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| $^a / _n$   | Buy 20 | Buy 40 | Buy 60 | Buy 80 |\n",
    "|:----------------:|:-----------:|:-----------:|:----------:|:-----------:|\n",
    "|Demand 10|$1000-1400+450=\\bf{50}$ | $1000-2680+1350=-330$ | $-650$ | $-970$ |\n",
    "|Demand 30 |$550$ |$\\bf{770}$ |$450$ |$130$ |\n",
    "|Demand 50 |$450$ |$1270$ |$\\bf{1550}$ |$1230$ |\n",
    "|Demand 70 |$350$ |$1170$ |$2050$ |$\\bf{2330}$ |\n",
    "\n",
    "\n",
    "Note the maximum of each payoff at the given demand levels is indicated in **bold**.\n",
    "\n",
    "Building the regret table yields:\n",
    "\n",
    "| $^a/_n$   | Buy 20 | Buy 40 | Buy 60 | Buy 80 |\n",
    "|:--:|:------:|:------:|:------:|:------:|\n",
    "|Demand 10 |$\\bf{50}-50=0$            |$380$|$700$|$1020$|\n",
    "|Demand 30 |$770-550=220$   | $770-770=0$        |$320$ |$640$ |\n",
    "|Demand 50 |$1550-450=1100$ |$280$ | $1550-1550=0$         |$320$ |\n",
    "|Demand 70 |$2230-350=1980$  |$1160$ |$280$ |$2330-2330=0$      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CHOOSING THE BEST ACTION **\n",
    "\n",
    "* Buying 60 bicycles is the best strategy under _minimax regret_.  Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISIONS UNDER RISK\n",
    "\n",
    "_Decisions under risk_ are made when there are known probabilities of the state of nature.  For example, we have the forecast for snow tomorrow and this information will inform our decision to wear boots or not.\n",
    "\n",
    "In order to model such decisions, we need to understand **Expected Return** (also known as **Expected Value**), denoted\n",
    "$\\mathit{ER}$.  Intuitively, expected return is the sum of the product of the probabilities of the states of nature and payoff for each given decision.  That is, given that we know the probabilities of the states of nature (probability of rain or no rain) and the payoffs for each state of nature for a given decision or act (wear boots, don't wear boots). The expected return for decision $a_i$ is then\n",
    "\n",
    "\\begin{equation}\n",
    "E[d_i] = \\sum_{j=1}^m p_{a_i, n_j} \\times \\Pr(n_j) \n",
    "\\end{equation}\n",
    "\n",
    "where $\\Pr(n_j)$ is the probability of the $j$th state of nature.\n",
    "\n",
    "Back to our weather example.  Let's say our weather app tells us  the probability of snow tomorrow is $0.3$, thus the expected return of wearing boots is $\\mathit{ER}_{\\mathit boots} = 0 \\times 0.3 + -10 \\times 0.7 = -7$.  Similarly, the expected return of not wearing boots is $ER_{\\mathit \\neg boots} = -5 \\times 0.3 + 5 \\times 0.7 = 2$.  If we use the strategy of _maximum expected return_, we would choose **not wear boots**.\n",
    "\n",
    "\n",
    "|         | snow $(0.3)$| no snow $(0.7)$ | **maximum expected return strategy** |\n",
    "|:-------:|:----:|:-------:|:--------------------:|\n",
    "|**boots**    | $0$  | $-10$ | $0 \\times 0.3 + -10 \\times 0.7 = -7$ |\n",
    "|**no boots** | $-5$ | $5$ | $-5 \\times 0.3 + 5 \\times 0.7 = \\bf{2}$ |\n",
    "\n",
    "\n",
    "What about our bicycle purchasing example?  Let's assume that Zed and Adrian take a look at the macro-economic indicators  estimate that the demand for bicycles this season for $10$, $30$, $50$, or $70$ bicycles have probabilities of $0.2$, $0.4$, $0.3$, and $0.1$ respectively.  \n",
    "\n",
    "* Buying 40 bicylces is the recommended action under risk using _maximum expected value_.  Why?  Compute this for yourself (don't look at the answer before you try).\n",
    "\n",
    "Computing the _maximum expected value_ is then just the `argmax` of the expected value:\n",
    "\n",
    "\\begin{equation} \n",
    "\\mathrm{argmax}\\:E[d] .\n",
    "\\end{equation}\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## SUPPLEMENTAL\n",
    "\n",
    "While we can do a lot of these computations by hand and with tables, why not try to program them and make reusable components for these things to be more valuable later.\n",
    "\n",
    "### PREREQUISITES\n",
    "You need a few things to get this code to run (but nothing unusual):\n",
    "\n",
    "* [Python 2.7.13](http://python.org/)\n",
    "* Anaconda for Python 2.7 [see download](https://continuum.io/download)\n",
    "    * we will be using [Pandas](https://) which is packaged with Anaconda\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_payoff(cost, demand, buy):\n",
    "    if demand > buy:\n",
    "        goodwill = 5*(demand-buy)\n",
    "        leftover = 0\n",
    "        sales = buy*100\n",
    "    else:\n",
    "        goodwill = 0\n",
    "        leftover = 45*(buy-demand)\n",
    "        sales = demand*100\n",
    "        \n",
    "    cost = cost*buy\n",
    "    \n",
    "    return sales - cost + leftover - goodwill "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the payoff computed, we will move to build the payoff table given the demand and actions scenario.  We'll use the `actions` list to encode the tuple for `(number_of_bicycles, purchase_cost_per_bicycle)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "demands = [10,30,50,70]\n",
    "actions = [(20,70),(40,67),(60,65),(80,64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to build a table of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| action/nature |  | | | |\n",
      "|:-------------:|--|--|--|--|\n",
      "|Demand 10 | 50  | -330  | -650  | -970  |\n",
      "|Demand 30 | 550  | 770  | 450  | 130  |\n",
      "|Demand 50 | 450  | 1270  | 1550  | 1230  |\n",
      "|Demand 70 | 350  | 1170  | 2050  | 2330  |\n"
     ]
    }
   ],
   "source": [
    "print \"| action/nature |  | | | |\"\n",
    "print \"|:-------------:|--|--|--|--|\"\n",
    "cols = []\n",
    "for d in demands:\n",
    "    print \"|Demand {}\".format(d),\n",
    "    row = []\n",
    "    for b,c in actions:\n",
    "        payoff = compute_payoff(c, d, b)\n",
    "        row.append(payoff)\n",
    "        print \"|\",payoff,\"\",\n",
    "    print \"|\"\n",
    "    cols.append(row)\n",
    "    \n",
    "df = pd.DataFrame(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHOOSING THE BEST STRATEGY\n",
    "A **maximax** strategy will choose to purchase 80 bicycles.  Why?\n",
    "\n",
    "A **maximin** strategy will choose to purchase 20. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LET'S EXPLORE THE REGET TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>-330</td>\n",
       "      <td>-650</td>\n",
       "      <td>-970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550</td>\n",
       "      <td>770</td>\n",
       "      <td>450</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450</td>\n",
       "      <td>1270</td>\n",
       "      <td>1550</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350</td>\n",
       "      <td>1170</td>\n",
       "      <td>2050</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3\n",
       "0   50  -330  -650  -970\n",
       "1  550   770   450   130\n",
       "2  450  1270  1550  1230\n",
       "3  350  1170  2050  2330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # show the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_regret = df.copy() # copy the payoff table, we will be turning it into a regret table later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maximax(df):\n",
    "    row_max = []\n",
    "    for i, row in df.iteritems():\n",
    "        amax = df[i].argmax()\n",
    "        row_max.append((amax, df.iloc[amax, i]))\n",
    "    return max(row_max, key=lambda(a,b): b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2330)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximax(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximin(df):\n",
    "    row_min = []\n",
    "    for i, row in df.iteritems():\n",
    "        amin = df[i].argmin()\n",
    "        row_min.append((amin, df.iloc[amin, i]))\n",
    "    return max(row_min,key=lambda(a,b): b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximin(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we can create a regret table as the algorithm shows, we take the max of each action and subtract the payoff for that payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, row in df_regret.iteritems():\n",
    "    df_regret.iloc[i] = max(df_regret.iloc[i])-df_regret.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>700</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>1160</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2     3\n",
       "0     0   380  700  1020\n",
       "1   220     0  320   640\n",
       "2  1100   280    0   320\n",
       "3  1980  1160  280     0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def minimax(df):\n",
    "    col_max = []\n",
    "    for i, row in df.iteritems():\n",
    "        amax = df[i].argmax()\n",
    "        col_max.append((i, df.iloc[amax, i]))\n",
    "    return min(col_max, key=lambda(a,b): b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 700)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimax(df_regret) # now we can compute the mininmax regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHALLENGE\n",
    "\n",
    "* Write the Python code independently for the maximum expected value."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "29px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
